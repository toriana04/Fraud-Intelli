name: Run IntelliFraud Scraper

on:
  schedule:
    - cron: "0 6 * * 0"   # Every Sunday at 6 AM UTC
  workflow_dispatch:      # Allow manual triggering

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      # --------------------------------------------------------------
      # 1. CHECKOUT REPO
      # --------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v3

      # --------------------------------------------------------------
      # 2. SET UP PYTHON
      # --------------------------------------------------------------
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # --------------------------------------------------------------
      # 3. INSTALL GOOGLE CHROME
      # --------------------------------------------------------------
      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg unzip
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt --fix-broken install -y
          google-chrome --version

      # --------------------------------------------------------------
      # 4. INSTALL MATCHING CHROMEDRIVER
      # --------------------------------------------------------------
      - name: Install ChromeDriver
        run: |
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d '.' -f 1)
          DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION")
          wget "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
          unzip chromedriver_linux64.zip
          sudo mv chromedriver /usr/local/bin/
          chromedriver --version

      # --------------------------------------------------------------
      # 5. INSTALL PYTHON DEPENDENCIES
      # --------------------------------------------------------------
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      # --------------------------------------------------------------
      # 6. IMPORT GITHUB SECRETS INTO ENVIRONMENT VARIABLES
      # --------------------------------------------------------------
      - name: Create environment variables
        run: |
          echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
          echo "SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}" >> $GITHUB_ENV

      # --------------------------------------------------------------
      # 7. RUN SELENIUM URL SCRAPER
      # --------------------------------------------------------------
      - name: Run Selenium URL Discovery
        run: |
          cd scraper
          python selenium_fetch_urls.py

      # --------------------------------------------------------------
      # 8. RUN PLAYWRIGHT ARTICLE EXTRACTOR
      # --------------------------------------------------------------
      - name: Run Playwright Article Extractor
        run: |
          cd scraper
          python playwright_extract_articles.py

      # --------------------------------------------------------------
      # 9. UPLOAD FINAL CSV TO SUPABASE
      # --------------------------------------------------------------
      - name: Upload CSV to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          cd scraper
          python upload_supabase.py
