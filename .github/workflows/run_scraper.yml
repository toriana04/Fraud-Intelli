name: Run IntelliFraud Scraper

on:
  schedule:
    - cron: "0 6 * * 0"   # Every Sunday at 6 AM UTC
  workflow_dispatch:      # Allow manual run

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install system dependencies
        run: |
          sudo apt update
          sudo apt install -y chromium-browser chromium-chromedriver

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Create environment variables
        run: |
          echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
          echo "SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}" >> $GITHUB_ENV

      - name: Run Selenium URL Discovery
        run: |
          cd scraper
          python selenium_fetch_urls.py

      - name: Run Playwright Article Extractor
        run: |
          cd scraper
          python playwright_extract_articles.py

      - name: Upload CSV to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          cd scraper
          python upload_supabase.py
